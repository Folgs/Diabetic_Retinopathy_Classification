{"cells":[{"cell_type":"code","source":["!pip install albumentations==0.4.6"],"metadata":{"id":"5B1tljZj60OY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install captum"],"metadata":{"id":"DPjTcfmL67Eg"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LiMGEgxga1eR"},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","\n","from PIL import Image\n","\n","import pandas as pd\n","\n","import os\n","import json\n","import numpy as np\n","from matplotlib.colors import LinearSegmentedColormap\n","\n","import torchvision\n","from torchvision import models\n","from torchvision import transforms\n","\n","from captum.attr import GradientShap\n","from captum.attr import visualization as viz\n","\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","import cv2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R7gcjSz7a1eU"},"outputs":[],"source":["if(torch.cuda.is_available()):\n","    print(\"SI\")\n","else:\n","    print(\"NO\")\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6s1HJmR7a1eV"},"outputs":[],"source":["model = models.resnet34(pretrained = True).to(device)\n","num_ftrs = model.fc.in_features\n","model.fc = nn.Linear(num_ftrs, 5)\n","\n","checkpoint = torch.load(\"/content/drive/MyDrive/run3/checkpoint.pth.tar\")\n","model.load_state_dict(checkpoint['state_dict'])\n","\n","model = model.eval()\n","model = model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_tKfDEtCa1eW"},"outputs":[],"source":["class Diabetic_Retinopathy_Dataset(Dataset): \n","  def __init__(self, transform=None):\n","    self.image_data = pd.read_csv(\"/content/drive/MyDrive/Projecte_RD/dades_imatges_act3.csv\", sep = ';', encoding=\"latin-1\")\n","    self.transform = transform \n","\n","  def __getitem__(self, i):\n","    ID_imatge, label = self.image_data.loc[i,['ID_Imatge','Retinopatia']]\n","    path = f\"/content/drive/MyDrive/Projecte_RD/dataset_processat/classe_{label}/{ID_imatge}\"\n","    image = cv2.imdecode(np.fromfile(path, dtype=np.uint8), cv2.IMREAD_UNCHANGED)\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    image = self.transform(image=image)[\"image\"]\n","    return image, label-1\n","\n","  def __len__(self):\n","    return len(self.image_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A7hC32xGa1eW"},"outputs":[],"source":["transform = A.Compose(\n","    [\n","        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n","        ToTensorV2(),\n","    ]\n",")\n","\n","transform_simple = transforms.Compose([\n"," transforms.ToTensor()\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7cE_gj-da1eW"},"outputs":[],"source":["#6311, 6312, 6906, 48770, 64488\n","i = 6311\n","image_data = pd.read_csv(\"/content/drive/MyDrive/Projecte_RD/dades_imatges_act3.csv\", sep = ';', encoding=\"latin-1\")\n","ID_imatge, label = image_data.loc[i,['ID_Imatge','Retinopatia']]\n","path = f\"/content/drive/MyDrive/Projecte_RD/dataset_processat/classe_{label}/{ID_imatge}\"\n","image = cv2.imdecode(np.fromfile(path, dtype=np.uint8), cv2.IMREAD_UNCHANGED)\n","image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","print(\"Class:\",label)\n","Image.fromarray(image)\n","\n","image_transform = transform_simple(image)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ie5LntaPa1eX"},"outputs":[],"source":["dataset = Diabetic_Retinopathy_Dataset(transform = transform)\n","dataset = torch.utils.data.Subset(dataset, [i])\n","dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bjvlLRqba1eX"},"outputs":[],"source":["for index_i, (images, target) in enumerate(dataloader):\n","    images = images.to(device)\n","    output = model(images)\n","    output = (torch.max(torch.exp(output), 1)[1])\n","    print(output)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HMD-NrXYa1eY"},"outputs":[],"source":["default_cmap = LinearSegmentedColormap.from_list('custom blue', \n","                                                 [(0, '#ffffff'),\n","                                                  (0.25, '#000000'),\n","                                                  (1, '#000000')], N=256)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0o_Dgzlta1eZ"},"outputs":[],"source":["torch.manual_seed(0)\n","np.random.seed(0)\n","\n","gradient_shap = GradientShap(model)\n","\n","# Defining baseline distribution of images\n","rand_img_dist = torch.cat([images * 0, images * 1])\n","\n","attributions_gs = gradient_shap.attribute(images,\n","                                          n_samples=50,\n","                                          stdevs=0.0001,\n","                                          baselines=rand_img_dist,\n","                                          target=output)\n","_ = viz.visualize_image_attr_multiple(np.transpose(attributions_gs.squeeze().cpu().detach().numpy(), (1,2,0)),\n","                                      np.transpose(image_transform.squeeze().cpu().detach().numpy(), (1,2,0)),\n","                                      [\"original_image\", \"heat_map\"],\n","                                      [\"all\", \"absolute_value\"],\n","                                      cmap=default_cmap,\n","                                      show_colorbar=True)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"colab":{"name":"Interpretability.ipynb","provenance":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}