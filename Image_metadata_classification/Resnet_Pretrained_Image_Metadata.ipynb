{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"to3LdzRaIOVr"},"outputs":[],"source":["import torch\n","from torchvision import transforms\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","import torchvision.models as models\n","\n","\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision.datasets as datasets\n","from torch.autograd import Variable\n","\n","import shutil\n","\n","import copy\n","import os\n","import numpy as np\n","\n","import itertools\n","import torch\n","from torchvision.utils import make_grid\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","\n","import datetime\n","from time import time\n","\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader, Subset\n","\n","import wandb\n","\n","if not torch.cuda.is_available():\n","    raise RuntimeError(\"You should enable GPU runtime!!\")\n","device = torch.device(\"cuda\")\n","torch.set_grad_enabled(True)\n","%matplotlib inline\n","\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import cohen_kappa_score\n","from sklearn.metrics import f1_score\n","import seaborn as sn\n","import itertools\n","\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","import cv2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZwKscy6XfpUH"},"outputs":[],"source":["# We use wandb to log our results\n","wandb.login()"]},{"cell_type":"markdown","metadata":{"id":"CPpb_wc5fpUI"},"source":["# 1. Data preprocesing\n","Read the execution parameters. Construct the dataloader and apply the transformations. We will use an impution of NaNs of Knn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Ahh1N5zfpUJ"},"outputs":[],"source":["first_run = False\n","second_run = False\n","num_run = 2004\n","epochs = 50\n","learning_rate= 1e-6\n","start = 82272\n","N_images = 82273\n","torch.backends.cudnn.benchmark = True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BuUsQSLxfpUJ"},"outputs":[],"source":["# If there is GPU, then use GPU.\n","import torch\n","if(torch.cuda.is_available()):\n","    print(\"SI\")\n","else:\n","    print(\"NO\")\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9PQDgOWLxJNo"},"outputs":[],"source":["image_data = pd.read_csv(\"C:/Users/48057074t/Desktop/Postgrau/prejecte/FonsUll/data_imputed_KNN_5.csv\", sep = ';', encoding=\"latin-1\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Wv7PxThIYmg"},"outputs":[],"source":["class Diabetic_Retinopathy_Dataset(Dataset): \n","  def __init__(self, transform=None):\n","\n","    self.image_data = pd.read_csv('FonsUll/data_imputed_KNN_5.csv', sep = ',', encoding=\"iso-8859-1\")\n","    self.image_data.columns = [\"ind\", \"ID_Image\", \"ID_Pacient\", \"Eye\", \"Retinopathy\", \"Age\", \"Sex\", \"HbA1c\", \"Total Cholesterol\", \"LDL\", \"HDL\", \"Systolic Arterial Pressure\", \"Diastolic Arterial Pressure\"] #, \"Cardiovascular Risk Score\"]\n","    self.target_col = \"Retinopathy\"\n","\n","    # METADATA\n","\n","    self.image_data = self.image_data.drop(\"ID_Pacient\", axis = 1)\n","    self.image_data = self.image_data.drop(\"Eye\", axis = 1)\n","    self.image_data = self.image_data.drop(\"ind\", axis = 1)\n","    \n","    self.image_data[\"Retinopathy\"] = self.image_data[\"Retinopathy\"].astype(int)\n","\n","    self.image_data[\"Age\"] = self.image_data[\"Age\"].astype(np.float32)\n","    self.image_data[\"Age\"] = (self.image_data[\"Age\"] -self.image_data[\"Age\"].mean())/self.image_data[\"Age\"].std()\n","\n","    self.image_data[\"Sex\"] = self.image_data[\"Sex\"].apply(lambda x: 1 if x == 'D' else 0).astype(np.float32)\n","\n","    self.image_data[\"HbA1c\"] = self.image_data[\"HbA1c\"].astype(np.float32)\n","    self.image_data[\"HbA1c\"] = (self.image_data[\"HbA1c\"] -self.image_data[\"HbA1c\"].mean())/self.image_data[\"HbA1c\"].std()\n","\n","    self.image_data[\"Total Cholesterol\"] = self.image_data[\"Total Cholesterol\"].astype(np.float32)\n","    self.image_data[\"Total Cholesterol\"] = (self.image_data[\"Total Cholesterol\"] -self.image_data[\"Total Cholesterol\"].mean())/self.image_data[\"Total Cholesterol\"].std()\n","\n","    self.image_data[\"LDL\"] = self.image_data[\"LDL\"].astype(np.float32)\n","    self.image_data[\"LDL\"] = (self.image_data[\"LDL\"] -self.image_data[\"LDL\"].mean())/self.image_data[\"LDL\"].std()\n","\n","    self.image_data[\"HDL\"] = self.image_data[\"HDL\"].astype(np.float32)\n","    self.image_data[\"HDL\"] = (self.image_data[\"HDL\"] -self.image_data[\"HDL\"].mean())/self.image_data[\"HDL\"].std()\n","    \n","    self.image_data[\"Systolic Arterial Pressure\"] = self.image_data[\"Systolic Arterial Pressure\"].astype(np.float32)\n","    self.image_data[\"Systolic Arterial Pressure\"] = (self.image_data[\"Systolic Arterial Pressure\"] -self.image_data[\"Systolic Arterial Pressure\"].mean())/self.image_data[\"Systolic Arterial Pressure\"].std()\n","\n","    self.image_data[\"Diastolic Arterial Pressure\"] = self.image_data[\"Diastolic Arterial Pressure\"].astype(np.float32)\n","    self.image_data[\"Diastolic Arterial Pressure\"] = (self.image_data[\"Diastolic Arterial Pressure\"] -self.image_data[\"Diastolic Arterial Pressure\"].mean())/self.image_data[\"Diastolic Arterial Pressure\"].std()\n","\n","    self.ID_Image = self.image_data[\"ID_Image\"]\n","    \n","    self.y = self.image_data[self.target_col].astype(np.float32)\n","\n","    # Image\n","    self.transform = transform \n","\n","  def __getitem__(self, i):\n","    ID_imatge, label = self.image_data.loc[i,['ID_Image','Retinopathy']]\n","    path = f\"C:/Users/48057074t/Desktop/Postgrau/prejecte/dataset_processat_full/classe_{label}/{ID_imatge}\"\n","    image = cv2.imdecode(np.fromfile(path, dtype=np.uint8), cv2.IMREAD_UNCHANGED)\n","    cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    image = self.transform(image=image)[\"image\"]\n","    \n","    if isinstance(i, torch.Tensor):\n","        i = i.tolist()\n","\n","    return image,  torch.tensor((self.image_data.drop(\"ID_Image\", axis = 1).drop(self.target_col, axis=1)).iloc[i].values), label-1\n","\n","  def __len__(self):\n","    return len(self.image_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aY9vruGAxJNq"},"outputs":[],"source":["train_transform = A.Compose(\n","    [\n","        A.HorizontalFlip(p=0.5),\n","        A.VerticalFlip(p=0.5),\n","        A.Rotate(limit = 180, p=1, border_mode=cv2.BORDER_REPLICATE),\n","        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n","        ToTensorV2(),\n","    ]\n",")\n","\n","val_transform = A.Compose(\n","    [\n","        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n","        ToTensorV2(),\n","    ]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2FT0NwIaxJNq"},"outputs":[],"source":["dataset = Diabetic_Retinopathy_Dataset()\n","validation_split = 0.2\n","shuffle_dataset = True\n","random_seed = 23\n","\n","# Creating data indices for training and validation splits:\n","dataset_size = len(dataset)\n","indices = list(range(dataset_size))\n","split = int(np.floor(validation_split * dataset_size))\n","if shuffle_dataset :\n","    np.random.seed(random_seed)\n","    np.random.shuffle(indices)\n","train_indices, val_indices = indices[split:], indices[:split]\n","\n","dataset_training = Diabetic_Retinopathy_Dataset(transform = train_transform)\n","dataset_validation = Diabetic_Retinopathy_Dataset(transform = val_transform)\n","\n","dataset_training = torch.utils.data.Subset(dataset_training, train_indices)\n","dataset_validation = torch.utils.data.Subset(dataset_validation, val_indices)\n","\n","dataloader_training = DataLoader(dataset_training, batch_size=18, shuffle=True, pin_memory= True)\n","dataloader_validating = DataLoader(dataset_validation, batch_size=18, shuffle=False, pin_memory= True)"]},{"cell_type":"markdown","metadata":{"id":"F1HecTHYfpUN"},"source":["# 2. Construct the model and metrics\n","\n","We use a Resnet34 pretrained and concate them with a CNN model for the tabular data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ozvxAYUHxJNr"},"outputs":[],"source":["class model(nn.Module):\n","\n","    def __init__(self, D_in = 8,  D_out=5, device=device):\n","\n","        super().__init__()\n","\n","        #image model\n","        self.mo = models.resnet34(pretrained = True).to(device)\n","        self.num_ftrs = self.mo.fc.in_features\n","        self.mo.fc = nn.Linear(self.num_ftrs, 5)\n","        self.checkpoint = torch.load('C:/Users/48057074t/Desktop/Postgrau/prejecte/checkpoint.pth.tar')\n","        self.mo.load_state_dict(self.checkpoint['state_dict'])\n","\n","        # #metadata model\n","        self.dropout = nn.Dropout(p = 0.25)\n","        self.relu = nn.ReLU()    \n","\n","        #CombinaciÃ³\n","        self.fc1_comb = nn.Linear(5+D_in, D_out)\n","\n","    def forward(self, tab, image):\n","\n","        # image model\n","        img = self.mo(image)\n","        img = self.relu(img)\n","\n","        # Combination\n","        x = torch.cat((img, tab), dim=1) # this is syntax where we concatenate the 1 channel from image data and 1 from tabular data i.e. 1+1 = 2\n","        x = self.fc1_comb(x)\n","\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bs8YuiXKxJNs"},"outputs":[],"source":["model = model(D_in = 8, D_out = 5, device = device).to(device)\n","optimizer = optim.Adam(model.parameters(), lr = learning_rate, weight_decay = 0)\n","criterion = nn.CrossEntropyLoss(weight = torch.tensor([75782/75782, 75782/4220, 75782/1737, 75782/307, 75782/227]).to(device))\n","model = model.to(device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kiNmc3S4Q-RM"},"outputs":[],"source":["def adjust_learning_rate(optimizer, epoch, original_lr):\n","    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n","    lr = original_lr * (0.1 ** (epoch // 50))\n","    # For some models, different parameters are in different groups with different lr\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = lr\n","\n","def correct_predictions(predicted_batch, label_batch):\n","    pred = predicted_batch.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n","    \n","    acum = pred.eq(label_batch.view_as(pred)).sum().item()\n","    return acum\n","\n","def save_checkpoint(state, is_best, filename='checkpoint.pth'):\n","    torch.save(state, filename)\n","    \n","    # save an extra copy if it is the best model yet\n","    if is_best:\n","        shutil.copyfile(filename, 'model_best.pth.tar')  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_DD1eW75fpUO"},"outputs":[],"source":["classes = ('1: Normal','2: RD Lleu','3: RD Moderada','4: RD Severa','5: Proliferativa')\n","def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","    print(cm)\n","    fig = plt.figure(figsize=(8,8))\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","\n","    return fig"]},{"cell_type":"markdown","metadata":{"id":"_ZuF3SfHxJNt"},"source":["# 3. Execution"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hutuAXqtK2xf"},"outputs":[],"source":["def train(train_loader, model, criterion, optimizer, device):\n","\n","    # Switch to train mode\n","    model.train()\n","    loss_mean = []\n","    acc_mean = []\n","\n","    for i, (images, input, target) in enumerate(train_loader):\n","        # Reset gradients\n","        optimizer.zero_grad()\n","\n","        #move images to gpu\n","        images = images.to(device)\n","        input = input.to(device)\n","        target = target.to(device)\n","\n","        # Compute output\n","        output = model(tab = input, image = images)\n","\n","        output = output.to(dtype = torch.float, device = device)\n","        target = target.to(dtype = int, device = device)\n","        \n","        loss = criterion(output,target)\n","        loss.backward()\n","        optimizer.step()\n","\n","        acc = 100 * (correct_predictions(output, target) / images.shape[0])\n","\n","        loss_mean.append(loss.item())\n","        acc_mean.append(acc)\n","\n","\n","    return np.mean(acc_mean), np.mean(loss_mean)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i7FIwkZzhhzo"},"outputs":[],"source":["def validate(val_loader, model, criterion, device):\n","\n","    # Switch to evaluate mode\n","    model.eval()\n","\n","    # We will save the values of the accuracies in this list to return the mean of the whole dataset at the end\n","    acc = 0\n","    loss = []\n","\n","    y_pred = []\n","    y_true = []\n","\n","    with torch.no_grad():  # We do not need to compute gradients\n","        for i, (images, input, target) in enumerate(val_loader):\n","\n","            images = images.to(device)\n","            input = input.to(device)\n","            target = target.to(device)\n","\n","            output = model(image = images, tab = input)\n","\n","            output = output.to(dtype = torch.float, device = device)\n","            target = target.to(dtype = int, device = device)\n","\n","            # loss\n","            loss.append(criterion(output, target).item())\n","\n","            # measure accuracy\n","            acc += correct_predictions(output, target)\n","\n","            # confusion matrix\n","            output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n","            y_pred.extend(output) # Save Prediction\n","            \n","            target = target.data.cpu().numpy()\n","            y_true.extend(target) # Save Truth\n","\n","    cf_matrix = confusion_matrix(y_true, y_pred)\n","    \n","    kappa = cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n","    \n","    f1_micro = f1_score(y_true, y_pred, zero_division=0, average = 'micro')\n","    \n","    f1_macro = f1_score(y_true, y_pred, zero_division=0, average = 'macro')\n","\n","    eval_acc = 100. * acc / len(val_loader.dataset)\n","\n","    return eval_acc, np.mean(loss), cf_matrix, kappa, f1_micro, f1_macro"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ePZG8JJAQc9W","scrolled":false},"outputs":[],"source":["wandb.finish() # This is needed just in case there was a wandb run from a previous execution\n","wandb.init(project=\"project_rd\")\n","wandb.run.name = f'run_{num_run}'\n","best_kappa = -1.\n","for epoch in range(epochs):\n","    adjust_learning_rate(optimizer, epoch, learning_rate)\n","\n","    acc_tr, loss_tr = train(dataloader_training, model, criterion, optimizer, device)\n","\n","    wandb.log({'Training/accuracy':acc_tr}, epoch)\n","    wandb.log({'Training/loss':loss_tr}, epoch)\n","\n","    acc, loss, cf_matrix, kappa, f1_micro, f1_macro = validate(dataloader_validating, model, criterion,device)\n","\n","    is_best = kappa > best_kappa\n","    best_kappa = max(kappa, best_kappa)\n","    \n","    wandb.log({'Validation/f1_micro': f1_micro},epoch)\n","    wandb.log({'Validation/f1_macro': f1_macro},epoch)\n","    wandb.log({'Kappa': kappa},epoch)\n","    wandb.log({'Validation/accuracy': acc},epoch)\n","    wandb.log({'Validation/loss':loss},epoch)\n","    wandb.log({'Conf_matrix':plot_confusion_matrix(cf_matrix, classes,normalize=True)}, epoch) \n","\n","    print(\"Iteracio\", epoch,\"completada. Validate loss\", loss, \"train loss\", loss_tr, \"Validate acc\", acc, \"train acc\", acc_tr, \"F1 score micro\", f1_micro, \"F1 score macro\", f1_macro, \"Kappa\", kappa)\n","\n","    save_checkpoint({\n","        'epoch': epoch + 1,\n","        'arch': \"resnet34\",\n","        'state_dict': model.state_dict(),\n","        'best_kappa': best_kappa,\n","        'optimizer' : optimizer.state_dict(),\n","    }, is_best, f\"checkpoint_{epoch}.pth.tar\")\n","\n","\n","wandb.finish()\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Resnet_Pretrained_Image_Metadata.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}